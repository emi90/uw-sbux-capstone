{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888d505c",
   "metadata": {},
   "source": [
    "<center><h1> Dynamic Contextualization for Starbucks Orders </h1></center>\n",
    "<center><h2> University of Washington </h2></center>\n",
    "<center><h3> MS in Data Science</h3></center>\n",
    "<center><h4> Capstone Project 2022 </h4></center>\n",
    "<p></p>\n",
    "<center> Leena Elamrawy | Christie L Gan | Corina Geier | Anant Rajeev | Emily Yamauchi </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0de66",
   "metadata": {},
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb4b4e",
   "metadata": {},
   "source": [
    "Starbucks deployed a new product recommendation system on their drive-thru screens at 4,000 Starbucks locations across the United States. The goal of this project is to redesign the recommendation system to include dynamic and contextual headlines to increase the conversation rate, thereby increasing sales and ultimately producing higher incremental tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf32c7",
   "metadata": {},
   "source": [
    "## Our solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a17dff",
   "metadata": {},
   "source": [
    "Our system predicts context labels to a requesting store based on conditions like the weather and the time of day. These context labels are then used to filter through potential headlines that would match these recommended products.\n",
    "\n",
    "Out of all the potential headlines, we picked the one that would give us the highest conversion rate. Our approach involved the use of reinforcement learning in the form of multi-armed bandits to determine the optimal headline choice.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d994df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from functions import utils, preprocessing, headlines\n",
    "from mab import multi_arm_bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45779eb0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60757b",
   "metadata": {},
   "source": [
    "We will be using the sample data from Nov. 11 2021 for this walkthrough.  \n",
    "\n",
    "As our smaller scope project takes 4 products given as inputs, the data we will be using is mostly static with the exception of weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b9576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root path\n",
    "dirpath = './data/sample_202111111'\n",
    "\n",
    "# path of parquet files\n",
    "product_df = utils.get_pq_df(dirpath + '/product.parquet/')\n",
    "store_df = utils.get_pq_df(dirpath + '/store.parquet/')\n",
    "ar_df = utils.get_pq_df(dirpath + '/action_reward.parquet/')\n",
    "weather_df = utils.get_pq_df(dirpath + '/weather.parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb28d36",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f9c21",
   "metadata": {},
   "source": [
    "The individual datasets can be merged on shared keys, and additional features can be extracted from product names.  \n",
    "\n",
    "Two important contexts we need to map are the `NotionalFlavor` and `form_codes`. Both are populated sparsely in the original dataset, so for items that do not have labels, we will attempt to derive them from the product names.  \n",
    "\n",
    "The third preprocessing step is to get the city and state names from the zipcodes given- we are using [this .csv file hosted on GitHub](https://raw.githubusercontent.com/scpike/us-state-county-zip/master/geo-data.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b6493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing- product df\n",
    "# get form codes from product names\n",
    "# if product names contain these keywords, map the form_codes as `Iced`, otherwise, `Hot`\n",
    "ice_keywords = ['refreshers', 'frappuccino', 'blended', 'cold', 'iced', 'bottled']\n",
    "product_df2 = preprocessing.get_form_codes(product_df, ice_keywords)\n",
    "\n",
    "# get notional flavor from product names\n",
    "prodcut_df2= preprocessing.get_notional_flavor(product_df2)\n",
    "\n",
    "# preprocessing- store df\n",
    "# get city state from zip codes\n",
    "store_df2 = preprocessing.get_zipcodes_from_csv(store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de8cff",
   "metadata": {},
   "source": [
    "## Inputs given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd58ed",
   "metadata": {},
   "source": [
    "To generate the dynamic headlines, we are given the following inputs:   \n",
    "\n",
    "- Recommended products: 4 items\n",
    "- Store number\n",
    "- Time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01627ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example- given recommended products\n",
    "\n",
    "products_given = ['chai-tea', \n",
    "                  'toasted-white-hot-chocolate', \n",
    "                  'clover-x-costa-rica-naranjo-hot',\n",
    "                  'pumpkin-spice-latte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bafcd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2- given recommended products, restricted to iced drinks \n",
    "\n",
    "iced_products = ['apple-crisp-frappuccino-blended-beverage',\n",
    "                 'iced-reserve-bar-caff√®-americano',\n",
    "                 'iced-espresso-classics---skinny-vanilla-latte',\n",
    "                'toasted-white-chocolate-mocha-frappuccino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c225fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs- time of day (in hours)\n",
    "\n",
    "hour1 = 8\n",
    "hour2 = 15\n",
    "hour3 = 18\n",
    "\n",
    "# inputs- store numbers\n",
    "# it was mostly sunny on our sample day in Seattle, hence could not test stores nearby with hot items\n",
    "\n",
    "store1 = 13507 # drivethru store in longview, WA\n",
    "store2 = 9447 # this is the one on 15th around interbay/magnolia bridge\n",
    "store3 = 53313 # the big reserve on michigan ave in chicago"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca05e9",
   "metadata": {},
   "source": [
    "## Generating headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0debec0",
   "metadata": {},
   "source": [
    "The string templates for the headlines are as follows:   \n",
    "\n",
    "```\n",
    "{weather_state} in {store_city}\n",
    "{daypart} {preferred_customer_mode}\n",
    "{weather_state} {preferred_customer_mode}\n",
    "{daypart} in {store_city}\n",
    "{weather_state} {daypart} in {store_city}\n",
    "```\n",
    "\n",
    "With 4 possible `preferred_customer_mode`, there are 11 total possible headlines from the template above.  \n",
    "\n",
    "Our `HeadlineGenerator` class will generate a list of available headlines based on the restrictions posed by the inputs.  \n",
    "\n",
    "For example, the mode \"Treat\" will not be applied to products that do not meet the \"Treat\" profile, or hot drinks will not be recommended on a sunny day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a4f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating HeadlineGenerator: takes the store, product, and weather dataset as inputs\n",
    "\n",
    "hg = headlines.HeadlineGenerator(store_df2, product_df2, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c960b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rainy in Longview',\n",
       " 'Morning in Longview',\n",
       " 'Rainy Morning in Longview',\n",
       " 'Morning Light Pick Me Up',\n",
       " 'Rainy Light Pick Me Up',\n",
       " 'Morning Treat',\n",
       " 'Rainy Treat',\n",
       " 'Morning Boost',\n",
       " 'Rainy Boost',\n",
       " 'Morning Flavor',\n",
       " 'Rainy Flavor']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate headlines given the store number, time of day, and the list of recommended items\n",
    "# try with store1\n",
    "\n",
    "wa_headlines = hg.get_headlines(store1, hour1, products_given)\n",
    "wa_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcf6f6",
   "metadata": {},
   "source": [
    "The `HeadlineGenerator` will also check to ensure that the products meet the `daypart` and `weather_state` restrictions- i.e. will not recommend a hot drink on a sunny day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f55b9f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Drink type does not match weather recommendation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12020/3242988327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# this will result in an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproducts_given\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ddt-project\\functions\\headlines.py\u001b[0m in \u001b[0;36mget_headlines\u001b[1;34m(self, store_num, hour, products)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mform_validity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__assert_form_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproducts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mcaffiene_validity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Exceeds recommended caffiene threshold\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mform_validity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Drink type does not match weather recommendation\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# headlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Drink type does not match weather recommendation"
     ]
    }
   ],
   "source": [
    "# this will result in an error\n",
    "hg.get_headlines(store2, hour1, products_given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c1b2a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny in Seattle',\n",
       " 'Morning in Seattle',\n",
       " 'Sunny Morning in Seattle',\n",
       " 'Morning Light Pick Me Up',\n",
       " 'Sunny Light Pick Me Up',\n",
       " 'Morning Treat',\n",
       " 'Sunny Treat',\n",
       " 'Morning Boost',\n",
       " 'Sunny Boost',\n",
       " 'Morning Flavor',\n",
       " 'Sunny Flavor']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will pass\n",
    "interbay_headlines = hg.get_headlines(store2, hour1, iced_products)\n",
    "interbay_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f8d9ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Exceeds recommended caffiene threshold",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12020/3017084669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# also check caffiene threshold for time of day\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# this will result in an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miced_products\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ddt-project\\functions\\headlines.py\u001b[0m in \u001b[0;36mget_headlines\u001b[1;34m(self, store_num, hour, products)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mcaffiene_validity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__assert_caffeine_validity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproducts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mform_validity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__assert_form_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproducts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mcaffiene_validity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Exceeds recommended caffiene threshold\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mform_validity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Drink type does not match weather recommendation\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Exceeds recommended caffiene threshold"
     ]
    }
   ],
   "source": [
    "# also check caffiene threshold for time of day\n",
    "# this will result in an error\n",
    "hg.get_headlines(store3, hour3, iced_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4904835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny in Chicago',\n",
       " 'Morning in Chicago',\n",
       " 'Sunny Morning in Chicago',\n",
       " 'Morning Light Pick Me Up',\n",
       " 'Sunny Light Pick Me Up',\n",
       " 'Morning Treat',\n",
       " 'Sunny Treat',\n",
       " 'Morning Boost',\n",
       " 'Sunny Boost',\n",
       " 'Morning Flavor',\n",
       " 'Sunny Flavor']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will pass\n",
    "chicago_headlines = hg.get_headlines(store3, hour1, iced_products)\n",
    "chicago_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46daeaeb",
   "metadata": {},
   "source": [
    "## Simulation: runing the Multi-Armed Bandits model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a62580",
   "metadata": {},
   "source": [
    "The multi-armed bandit problem models an agent that wants to simultaneously acquire new knowledge (exploration) and optimize decisions based on existing knowledge (exploitation).\n",
    "\n",
    "The information (customers purchasing the recommended products or not) gained from the data gathered will shift the distribution in different ways to reflect an accurate reward model.\n",
    "\n",
    "The model recursively continues to learn about which headlines are contributing to a higher conversion rate. This then allows Starbucks to make a store-by-store decision with regards to which headlines they want to display on that drive-thru.   \n",
    "\n",
    "We were faced with the problem of a cold start (unsupervised learning) due to the lack of historical data regarding screen engagement with these newly generated headlines. To combat that, we adopted the Thompson Sampling algorithm, which uses a beta distribution as a parametric assumption to model the prior unknown distribution. The model recursively continues to learn and adjusts the reward model as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1945cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters: headlines, num_turns, lbound=0.01, ubound=0.15\n",
    "# initiate the mab model\n",
    "\n",
    "mab = multi_arm_bandits.MultiArmBandits(wa_headlines, num_turns=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "137dc78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline 0 was chosen 40.0 times\n",
      "Headline 1 was chosen 27.0 times\n",
      "Headline 2 was chosen 29.0 times\n",
      "Headline 3 was chosen 41.0 times\n",
      "Headline 4 was chosen 60.0 times\n",
      "Headline 5 was chosen 40.0 times\n",
      "Headline 6 was chosen 521.0 times\n",
      "Headline 7 was chosen 82.0 times\n",
      "Headline 8 was chosen 27.0 times\n",
      "Headline 9 was chosen 74.0 times\n",
      "Headline 10 was chosen 59.0 times\n",
      "\n",
      "Overall conclusion: best headline is 6\n",
      "\n",
      "Rainy Treat\n"
     ]
    }
   ],
   "source": [
    "# run the simulation\n",
    "# returns the conversions and fails\n",
    "\n",
    "mab_conversion, mab_fails = mab.simulation(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35b86dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_interbay = multi_arm_bandits.MultiArmBandits(interbay_headlines, num_turns=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e305606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline 0 was chosen 133.0 times\n",
      "Headline 1 was chosen 141.0 times\n",
      "Headline 2 was chosen 37.0 times\n",
      "Headline 3 was chosen 107.0 times\n",
      "Headline 4 was chosen 28.0 times\n",
      "Headline 5 was chosen 148.0 times\n",
      "Headline 6 was chosen 66.0 times\n",
      "Headline 7 was chosen 65.0 times\n",
      "Headline 8 was chosen 128.0 times\n",
      "Headline 9 was chosen 41.0 times\n",
      "Headline 10 was chosen 106.0 times\n",
      "\n",
      "Overall conclusion: best headline is 5\n",
      "\n",
      "Morning Treat\n"
     ]
    }
   ],
   "source": [
    "mab_interbay_conv, mab_interbay_fails = mab_interbay.simulation(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3af52",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60303429",
   "metadata": {},
   "source": [
    "We are currently setting the parameters using an arbitrary threshold for many of the methods- such as the caffiene, sugar, calorie thresholds, or the distribution of the simulated headlines. We could take a better approach to fine-turning these parameters.   \n",
    "\n",
    "Our methodology to categorize the iced and hot drinks can also be improved.  \n",
    "\n",
    "Another major next step would be to generate the recommended drinks for each store based on the `action_rewards` dataset- due to project timeline constraints, we accepted the products as given inputs, but had we more time we would like to find and learn the best products."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
